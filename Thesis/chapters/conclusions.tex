\chapter{Summary and Future Work}

\section*{Summary of Results}
We demonstrate an end-to-end system to learn embeddings in a Euclidean space using triplet loss for recognition and clustering using triplet loss. Our network achieves a $60.4\%$ six-class classification accuracy and 90.4\% binary classification accuracy. Our work demonstrates that using deep metric learning and deep feature embedding networks, particularly those trained on the triplet loss, can help learn more about EEG signals. 

In particular, since our method involves clustering the EEG signals in an embedding space as opposed to directly classifying them, there are many more operations that can be done. For example, it may be possible to discover new types of EEGs with no extra training. In the case a new type of signal is discovered outside of the embedding, it might be possible to further train the current model in order for it to learn the new type of signal. Furthermore, the method used in this paper can be used to classify a given signal as either seizure-like or noise-like, help automated labeling systems to identify anomalies in EEGs and direct a physician's attention towards these anomalies without the help of an expert in the medical field. The system can be implemented in a seizure detection device for patients prone to seizures to automatically deploy counter measures and call emergency services in order to maximize patient survival rate.

\section*{Future Work}

We should further analyze these results to improve this system. For example, we can do an in-depth comparison between the features in baseline's latent spaces' penultimate layer and the features in the clustering network's latent spaces' final layer. Each network has different accuracies even though they both have identical functional forms. Therefore, a comparison between the two latent spaces speaks directly to the training method for selecting the parameters. 

Since the TUH corpus includes natural language physician notes, it may be possible to incorporate these notes to improve the clusters forming in the latent space. We can use keywords such as ``seizure'' or ``epilepsy'' to bias the network to push the sample towards a cluster containing seizures. \citet{magnetloss} work provides a way to do this and we can use it as an inspiration to further improve the clustering through adaptive density discrimination. Perhaps, more advanced versions of the triplet loss, such as the one \citet{lifted_structure_embedding} provide, can improve improve latent space learned by the neural network. 

While our system is able to accurately classify the labels, further tests should be conducted to determine its ability to generalize to new labels. Optimally, the network should be able to detect new labels and classify them accordingly. One way to determine the networks' generalization property is to train on five labels and keep the sixth label as a holdout. A generalizing network will be able to cluster the data in a manner such that algorithms that recognize clusters (e.g. Affinity Propagation \cite{frey2007clustering} and Mean Shift \cite{comaniciu2002mean} clustering algorithms) will be able to detect the sixth without any prior information.

We also can hypothesize that it may be useful to augment the current convolutional architecture with a decoder network to create an autoencoder and train the autoencoder with both triplet loss as well as the mean-squared-error loss. Autoencoders typically are used to reduce dimensionality of data without losing too much information about the input. Combining this with the triplet loss may help learn richer latent spaces involving features that contribute to high information gain. An extra hyperparameter will probably be introduced to control how much the triplet loss affects the encoding learned by the new network. 

Finally, it might be beneficial for us to explore how the same components in this system perform with different types of data, such as MRIs and X-Rays.  Although there are a few sources of errors, our system still has a relatively high accuracy and could serve as a stepping stone in directly analyzing, structuring and organizing medical data. 