\chapter{Summary \& Future Work}

\section*{Summary of Results}
We demonstrated an end-to-end system to learn embeddings in a Euclidean space for recognition and clustering using triplet loss. Our network managed to achieve a $60.4\%$ six-class classification accuracy and 90.4\% binary classification accuracy. Our work demonstrates that using deep metric learning and deep feature embedding networks, particularly those trained on the triplet loss, may be used to help learn more about EEG signals. 

In particular, since our method involves clustering the EEG signals in an embedding space as opposed to directly classifying them, there are a lot more operations that can be done. For example, it may be possible to discover new types of EEGs with no extra training. In the case a new type of signal is discovered outside of the embedding, it might be possible to further train the current model in order for it to learn the new type of signal. Furthermore, the method used in this paper can be used to classifiy a given signal as either seizure-like or noise-like, help automated labeling systems to identify anomalies in EEGs and direct a physician's attention towards these anomalies possibly without the help of an expert in the field. The system can possibly be implemented in a seizure detection device for patients prone to seizures to automatically deploy counter measures and call emergency services in order to maximize survival rate.

\section*{Future Work}

Further analysis can be done to determine the usage of this system. For example, we can do an in-depth comparison between the features learned in baseline's latent spaces' penultimate layer and the features learned in the clustering network's latent spaces' final layer. Each network had different accuracies even though they both had identical functional forms. Therefore, a comparison between the two latent spaces speaks directly to the training method for selecting the parameters. 

Since the TUH corpus includes natural language physician notes, it may be possible to incorporate these notes to improve the clustering provided by the network. Keywords such as ``seizure'' or ``epilepsy'' can be used to bias the network to push the sample towards a cluster containing seizures. We could look at the work provided by \citet{magnetloss} as an inspiration to further improve the clustering through adaptive density discrimination. Perhaps, more advanced versions of the triplet loss, such as the one described by \citet{lifted_structure_embedding}, to experiment and find out whether they may improve latent space learned by the neural network. 

While our system is able to accurately classify the labels, further tests should be conducted to determine its ability to generalize to new labels. Optimally, the network should be able to detect new labels and classify them accordingly. One way to determine the networks' generalization property is to train on five labels and keep the sixth label as a holdout. A generalizing network will be able to cluster the data in a manner such that algorithms that recognize clusters (e.g. Affinity Propagation \cite{frey2007clustering} and Mean Shift \cite{comaniciu2002mean} clustering algorithms) will be able to detect the sixth without any prior information.

We also can hypothesize that it may be useful to augment the current convolutional architecture with a decoder network to create an autoencoder and train the autoencoder with both triplet loss as well as the mean-squared-error loss. Autoencoders typically are used to reduce dimensionality of data without losing too much information about the input. Combining this with the triplet loss may help learner richer latent spaces involving features that contribute to high information gain. An extra hyperparameter will probably be introduced to control how much the triplet loss affects the encoding learned by the new network. 

Finally, it might be beneficial for us to explore how the same components in this system performs with different types of data, such as MRIs and X-Rays.  Although there are a few sources of errors, our system still has a relatively high accuracy and could serve as a stepping stone in directly analyzing, structuring and organizing medical data. 





% % Application
% % Questions
% % Analysis


% %% NEW CONCLUSION %%
% We demonstrated a method to learn embeddings for EEG signals in an end-to-end fashion. While our system is able to accurately classify the known labels in the TUH dataset, we intend to analyze it for outliers detection and one-shot learning on classes available in the training set. Since our proof-of-concept network is small, it is possible that a more expressive network could obtain better results.

% We intend to do an in depth comparison between the baseline embeddings space (i.e features produced by the penultimate layer) and the experimental one. Each is predicted by functions with identical forms for different parameters. Therefore a comparison between the two embedding spaces speaks directly to the training method for selecting the parameters.

% As the TUH corpus also includes physician notes, we would like to investigate ways to incorporate these notes into a cohort retrieval scheme. This could be done by learning a similar embedding for the text data and then performing a clustering on a joint embedded space. Another possible area for investigation would be to leverage an adaptive density discrimination technique \citet{magnetloss} to shape clusters in the EEG embedding space using the annotations as side information. 


% Finally, we can attempt to use network on other types of raw medical data such as MRIs and X-Rays. Medical researchers can attempt to use a triplet loss clustering network to cluster these images in order to recognize deeper meaning while using a (relatively) low dimensional embedding space. Differentiating between different types of ailments in MRIs and X-Rays can help in developing an automated system that can diagnose a patient given little information. 


% Finally, we can attempt to use this system with other types of raw medical data such, such as MRIs. We can try to modify this network such that it works for true image data and see whether it can be used to identify meaningful relationships in the data. We 

% %% MY OLD CONCLUSION %%

% We provide a method to directly learn an embedding space of EEG signals in a Euclidean space for recognition and clustering. This method is useful in the field because it can be used to determine the causes of certain ailments as opposed to their symptoms. Furthermore, this type of embedding space can be queried when needed to determine certain similarities of a certain patients EEG data with the data of another person's EEG data. Doing this will help recognize treatments that may be more effective than the ones currently being used in medicine.  Our end-to-end system can be used for all of the above purposes. 

% While our system is able to accurately classify the labels, further tests should be conducted to determine its ability to generalize to new labels. Optimally, the network should be able to detect new labels and classify them accordingly. One way to determine the networks' generalization property is to train on five labels and keep the sixth label as a holdout. A generalizing network will be able to classify the sixth label as a new type of label at inference time. '

% It would also be wise to attempt to incorporate a recurrent relationship between the neurons in the network in order for a better prediction of the embedding. After all, the data that we are dealing with is time dependent and recurrent neural networks are top of the line for that even if they can be unstable at times. 

% Future work can be done to use this system in other types of raw medical data, such as MRIs. Medical researchers can attempt to use a triplet loss clustering network to cluster these images in order to recognize deeper meaning while using a (relatively) low dimensional embedding space.