\chapter{Introduction}
\vspace{-1cm}

The healthcare industry commonly stores diverse instrumentation signals such as EEGs\nomenclature{EEG}{Electroencephalography}, EKGs\nomenclature{EKG}{Electrocardiogram}, MEGs\nomenclature{MEG}{Magnetoencephalography}, X-Rays, MRIs\nomenclature{MRI}{Magnetic Resonance Imaging}, and CAT scans in a variety of digital formats commonly referred to as Electronic Medical Records (EMRs\nomenclature{EMR}{Electronic Medical Records}).  These records can also contain natural language notes from medical professionals. It is difficult to perform complex information retrieval on these records. Rich information retrieval may open up the ability to compare and contrast patient records en-masse leading to new understandings of disease pathologies. For example, while the healthcare industry possesses a large amount of data on Alzheimer's Disease, a common chronic neurodegenerative disorder, medical professionals cannot find the underlying cause of this disease and why it worsens over time. If such data can be transformed into an accessible and patient invariant format such that different patients with similar cases can be found easily, medical professionals may be able to pinpoint the cause of the disease and discover better treatments. Towards this goal, \citet{piccone} have demonstrated a system that can automatically discover, time-align and annotate EEG events to perform cohort retrieval, the task of efficiently finding a group of observations which share defining characteristics with a sample observation. The signal event detection and classification work in \citet{piccone} uses Hidden Markov Models, which work well with sequential data. Although this model achieved $91.4\%$ sensitivity and $8.5\%$ specificity on the signal classification task, it is impossible to infer similarity of samples from the output of a classifier. Since similarity is a key factor in cohort retrieval, it is important to incorporate it into any cohort retrieval scheme.

In contrast to the work done by \citet{piccone}, we optimize a deep neural network using a triplet loss function that results in a reduced dimensionality latent space which minimizes the distance between similar signals and maximizes the distance between dissimilar signals. In doing so, we expect clusters of signals to form in the latent space characterized by features that have a meaningful interpretation of the original signals. At inference time, we can use the network to map new EEG signals onto this latent space for querying. New samples could be presented to this system and mapped into the latent space. After this mapping, clustering or other distance-based methods could be employed to find similar EEG records as part of a cohort retrieval system. It is hoped that this system can be used to discover significant relations between diseases in medicine.  

We organize the rest of this thesis in the following way. In \cref{bckgnd},  we discuss background information on machine learning needed to understand our work. In \cref{relwork}, we review the literature relevant to deep metric learning and deep feature embedding techniques. In \cref{dataresources}, we describe our data and how we organized it for ease of access. In \cref{expres}, we describe our final models, their quantitative and qualitative characteristics, our experimental results and our analysis of those results. 
